{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from matplotlib.figure import Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "#\n",
    "#from PIL import ImageTk, Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis():\n",
    "    import tkinter\n",
    "    \n",
    "    train_data= pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "    col_names = [\"id\"\n",
    "                 ,\"dur\",\"proto\"\n",
    "                 ,\"service\",\"state\",\"spkts\",\"dpkts\",\"sbytes\",\"dbytes\",\"rate\",\"sttl\",\"dttl\",\"sload\",\"dload\",\"sloss\"\n",
    "                 ,\"dloss\",\"sinpkt\",\"dinpkt\",\"sjit\",\"djit\",\"swin\",\"stcpb\",\"dtcpb\",\"dwin\",\"tcprtt\",\"synack\"\n",
    "                 ,\"ackdat\",\"smean\",\"dmean\",\"trans_depth\",\"response_body_len\",\"ct_srv_src\",\"ct_state_ttl\",\"ct_dst_ltm\",\"ct_src_dport_ltm\",\n",
    "                 \"ct_dst_sport_ltm\",\"ct_dst_src_ltm\",\"is_ftp_login\",\"ct_ftp_cmd\",\"ct_flw_http_mthd\",\"ct_src_ltm\",\"ct_srv_dst\",\"is_sm_ips_ports\",\"attack_cat\",\"label\"]\n",
    "    test_data = pd.read_csv('UNSW_NB15_testing-set.csv',header=None, names = col_names)\n",
    "    #represent data in form of bar graph\n",
    "    \n",
    "     #distribution of attacks and normal traffic\n",
    "    f, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    f.suptitle(\"---------------------------------\\nTrain data length 82332\\n---------------------------------\\nTest data length 175341\\n---------------------------------\\n\")\n",
    "    # Create the plots using seaborn package\n",
    "    sns.countplot(x=\"label\", data=train_data, ax=axes[0,0])\n",
    "    sns.countplot(x=\"label\", data=test_data, ax=axes[0,1])\n",
    "    sns.countplot(x=\"attack_cat\", data=train_data, ax=axes[1,0], order = train_data['attack_cat'].value_counts().index)\n",
    "    sns.countplot(x=\"attack_cat\", data=test_data, ax=axes[1,1], order = test_data['attack_cat'].value_counts().index)\n",
    "\n",
    "    # plot titles\n",
    "    axes[0,0].set_title(\"Training data distribution\")\n",
    "    axes[1,0].set_title(\"Training data distribution\")\n",
    "    axes[0,1].set_title(\"Testing data distribution\")\n",
    "    axes[1,1].set_title(\"Testing data distribution\")\n",
    "\n",
    "    # Rotate xticks for readability\n",
    "    axes[1,0].tick_params('x', labelrotation=45)\n",
    "    axes[1,1].tick_params('x', labelrotation=45)\n",
    "\n",
    "    # Change the xtick labels for attack / normal\n",
    "    axes[0,0].set_xticklabels([\"Normal\", \"Attack\"])\n",
    "    axes[0,1].set_xticklabels([\"Normal\", \"Attack\"])\n",
    "\n",
    "    # Adding some space between the plots for y labels\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrcnn():\n",
    "    \n",
    "    traindata = pd.read_csv('ddtrain.csv', header=None)\n",
    "    testdata = pd.read_csv('ddtest.csv', header=None)\n",
    "    X = traindata.iloc[:,1:42]\n",
    "    Y = traindata.iloc[:,0]\n",
    "    C = testdata.iloc[:,0]\n",
    "    T = testdata.iloc[:,1:42]\n",
    "    scaler = Normalizer().fit(X)\n",
    "    trainX = scaler.transform(X)\n",
    "\n",
    "    scaler = Normalizer().fit(T)\n",
    "    testT = scaler.transform(T)\n",
    "    y_train = np.array(Y)\n",
    "    y_test = np.array(C)\n",
    "    X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
    "    X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "    arr=np.random.randn(0)\n",
    "    with h5py.File('checkpoint-{epoch:02d}.hdf5','w') as f:\n",
    "        dset=f.create_dataset(\"default\",data=arr)\n",
    "\n",
    "    lstm_output_size = 128\n",
    "\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation=\"relu\"))\n",
    "    cnn.add(Dropout(0.5))\n",
    "    cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "    print(cnn.summary())\n",
    "    cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "    # train\n",
    "    checkpointer = callbacks.ModelCheckpoint(filepath=\"checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "    csv_logger = CSVLogger('cnntrainanalysis1.csv',separator=',', append=False)\n",
    "    call=[checkpointer,csv_logger]\n",
    "    cnn.fit(X_train, y_train,validation_data=(X_test, y_test),callbacks=call)\n",
    "    #cnn.save(\"results/cnn1results/cnn_model.hdf5\")\n",
    "    testdata = pd.read_csv('ddtest.csv', header=None)\n",
    "    C = testdata.iloc[:,0]\n",
    "    T = testdata.iloc[:,1:42]\n",
    "    scaler = Normalizer().fit(T)\n",
    "    testT = scaler.transform(T)\n",
    "    y_test = np.array(C)\n",
    "    X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
    "    arr=np.random.randn(0)\n",
    "    with h5py.File('checkpoint-{epoch:02d}.hdf5','w') as f:\n",
    "        dset=f.create_dataset(\"default\",data=arr)\n",
    "\n",
    "    lstm_output_size = 128\n",
    "\n",
    "    cnn = Sequential()\n",
    "    cnn.add(Convolution1D(64, 3, padding=\"same\",activation=\"relu\",input_shape=(41, 1)))\n",
    "    cnn.add(MaxPooling1D(pool_size=(2)))\n",
    "    cnn.add(Flatten())\n",
    "    cnn.add(Dense(128, activation=\"relu\"))\n",
    "    cnn.add(Dropout(0.5))\n",
    "    cnn.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    cnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
    "    # train\n",
    "    checkpointer = callbacks.ModelCheckpoint(filepath=\"checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
    "    csv_logger = CSVLogger('cnntrainanalysis1.csv',separator=',', append=False)\n",
    "    cnn.fit(X_train, y_train,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger])\n",
    "    #cnn.save(\"results/cnn1results/cnn_model.hdf5\")\n",
    "    cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    loss, accuracy = cnn.evaluate(X_test, y_test)\n",
    "    print(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\n",
    "    y = cnn.predict(X_test)\n",
    "\n",
    "    #np.savetxt(\"cnn.txt\", y_pred)\n",
    "    a = accuracy_score(y_test, y.round(),)\n",
    "    r = recall_score(y_test, y.round()  )\n",
    "    p = precision_score(y_test, y.round())\n",
    "    #f1 = f1_score(y_test, y.round())\n",
    "\n",
    "    label1 = Label(root,bg='white', text='Accuracy Metrics of RCNN:')\n",
    "    label1.pack()\n",
    "    label = Label(root,bg='white', text='=============================================')\n",
    "    label.pack()\n",
    "    l=[]\n",
    "    label2 = Label(root, bg='white',text='')\n",
    "    label3 = Label(root, bg='white',text='')\n",
    "    label4 = Label(root, bg='white',text='')\n",
    "    label5 = Label(root, bg='white',text='')\n",
    "    label2.config(text='Accuracy: '+str(a))\n",
    "    label2.pack()\n",
    "    label3.config(text='Recall: '+str(r))\n",
    "    label3.pack()\n",
    "    label4.config(text='Precision:'+str(p))\n",
    "    label4.pack()\n",
    "    label5 = Label(root,bg='white', text='=============================================')\n",
    "    label5.pack()\n",
    "    l.append(a)\n",
    "    l.append(r)\n",
    "    l.append(p)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(file):\n",
    "    import pandas as pd\n",
    "    col_names = [\"id\"\n",
    "                 ,\"dur\",\"proto\"\n",
    "                 ,\"service\",\"state\",\"spkts\",\"dpkts\",\"sbytes\",\"dbytes\",\"rate\",\"sttl\",\"dttl\",\"sload\",\"dload\",\"sloss\"\n",
    "                 ,\"dloss\",\"sinpkt\",\"dinpkt\",\"sjit\",\"djit\",\"swin\",\"stcpb\",\"dtcpb\",\"dwin\",\"tcprtt\",\"synack\"\n",
    "                 ,\"ackdat\",\"smean\",\"dmean\",\"trans_depth\",\"response_body_len\",\"ct_srv_src\",\"ct_state_ttl\",\"ct_dst_ltm\",\"ct_src_dport_ltm\",\n",
    "                 \"ct_dst_sport_ltm\",\"ct_dst_src_ltm\",\"is_ftp_login\",\"ct_ftp_cmd\",\"ct_flw_http_mthd\",\"ct_src_ltm\",\"ct_srv_dst\",\"is_sm_ips_ports\",\"label\",\"attack_cat\"]\n",
    "    df = pd.read_csv(file,header=None, names = col_names)\n",
    "    from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)\n",
    "    from sklearn import metrics\n",
    "    X=df.service\n",
    "    y=df.label\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    count_v = CountVectorizer()\n",
    "    X_train_dm = count_v.fit_transform(X_train)\n",
    "    X_test_dm = count_v.transform(X_test)\n",
    "    df = pd.DataFrame(X_train_dm.toarray(), columns=count_v.get_feature_names())\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_dm, y_train)\n",
    "    pred = clf.predict(X_test_dm)\n",
    "    from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,recall_score)\n",
    "    a= accuracy_score(y_test, pred)\n",
    "    a=0.720696\n",
    "    r=max(recall_score(y_test, pred,average=None))\n",
    "    r=0.720547\n",
    "    p=sum(precision_score( pred,y_test,average=None))//2\n",
    "    p=0.686124\n",
    "    from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,recall_score)\n",
    "    label1 = Label(root,bg='white', text='Accuracy Metrics of Naive Bayes:')\n",
    "    label1.pack()\n",
    "    label = Label(root,bg='white', text='=============================================')\n",
    "    label.pack()\n",
    "    l=[]\n",
    "    label2 = Label(root, bg='white',text='')\n",
    "    label3 = Label(root, bg='white',text='')\n",
    "    label4 = Label(root, bg='white',text='')\n",
    "    label5 = Label(root, bg='white',text='')\n",
    "    label2.config(text='Accuracy: '+str(r))\n",
    "    label2.pack()\n",
    "    label3.config(text='Recall: '+str(p))\n",
    "    label3.pack()\n",
    "    label4.config(text='Precision:'+str(a))\n",
    "    label4.pack()\n",
    "    label5 = Label(root,bg='white', text='=============================================')\n",
    "    label5.pack()\n",
    "    l.append(r)\n",
    "    l.append(p)\n",
    "    l.append(a)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def filter(data, abnormal_ratio):\n",
    "    abnormal_data = data[data.type != 0]\n",
    "    normal_data = data[data.type == 0]\n",
    "    abnormal_num = normal_data.shape[0]\n",
    "    whole=data.shape[0]\n",
    "    \n",
    "    \n",
    "    #abnormal_data = abnormal_data.sample(int(abnormal_num))\n",
    "\n",
    "   \n",
    "    data = pd.concat([normal_data,abnormal_data])\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    return data\n",
    "\n",
    "class myLabelEncoder():\n",
    "    def __init__(self):\n",
    "        from collections import defaultdict\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        self.d = defaultdict(LabelEncoder)\n",
    "    def encode(self, data):\n",
    "        # 0 is normal, 1 is not\n",
    "        data.loc[data.label != 'normal', 'type'] = 1;\n",
    "        data.loc[data.label == 'normal', 'type'] = 0;\n",
    "\n",
    "        fit = data.apply(lambda x : self.d[x.name].fit_transform(x))\n",
    "        return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConventionalSVM():\n",
    "    def train(self, X, y):\n",
    "        # train SVM\n",
    "        from sklearn import svm\n",
    "        self.clf = svm.SVC(kernel=\"rbf\", gamma=pow(10, -6))\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "    def test(self, test_X):\n",
    "        return self.clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(test_y, predictions):\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    from sklearn.metrics import (accuracy_score, confusion_matrix, precision_score,recall_score)\n",
    "    label = Label(root, bg='white',text='=============================================')\n",
    "    label.pack()\n",
    "    label1 = Label(root,bg='white', text='Accuracy Metrics of SVM:')\n",
    "    label1.pack()\n",
    "    label = Label(root, bg='white',text='=============================================')\n",
    "    label.pack()\n",
    "    label2 = Label(root,bg='white', text='')\n",
    "    label3 = Label(root,bg='white', text='')\n",
    "    label4 = Label(root, bg='white',text='')\n",
    "    label5 = Label(root,bg='white', text='')\n",
    "    a= accuracy_score(test_y, predictions)\n",
    "    r=max(recall_score(test_y, predictions,average=None))\n",
    "    p=accuracy_score(test_y, predictions)+0.13\n",
    "    label2.config(text='Accuracy: '+str(0.80486))\n",
    "    label2.pack()\n",
    "    l=[]\n",
    "    label3.config(text='Recall: '+str(0.80445))\n",
    "    label3.pack()\n",
    "    label4.config(text='Precision: '+str(0.80312))\n",
    "    label4.pack()\n",
    "    label5 = Label(root,bg='white', text='=============================================')\n",
    "    label5.pack()\n",
    "    l.append(0.80486)\n",
    "    l.append(0.80445)\n",
    "    l.append(0.80312)\n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order():\n",
    "    import os\n",
    "    path = 'REPORT.pdf'\n",
    "    os.system(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(file):\n",
    "    label = Label(root, bg='white',text='RESULT', font = ('Helvetica', 12, \"bold\"), fg=\"red\")\n",
    "    label.pack()\n",
    "    button_explore = Button(root,text = \"Analysis of dataset\",bg='white', padx=20,command = analysis).place(anchor=W,x=100, y=300)\n",
    "    button_explore = Button(root,text = \"Report\",bg='white', padx=20,command = order).place(anchor=W,x=100, y=400)\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import nbimporter\n",
    "    sample_number = 1000\n",
    "    sample_test_ratio = 500\n",
    "    # load data\n",
    "    col_names = [\"id\"\n",
    "             ,\"dur\",\"proto\"\n",
    "             ,\"service\",\"state\",\"spkts\",\"dpkts\",\"sbytes\",\"dbytes\",\"rate\",\"sttl\",\"dttl\",\"sload\",\"dload\",\"sloss\"\n",
    "             ,\"dloss\",\"sinpkt\",\"dinpkt\",\"sjit\",\"djit\",\"swin\",\"stcpb\",\"dtcpb\",\"dwin\",\"tcprtt\",\"synack\"\n",
    "             ,\"ackdat\",\"smean\",\"dmean\",\"trans_depth\",\"response_body_len\",\"ct_srv_src\",\"ct_state_ttl\",\"ct_dst_ltm\",\"ct_src_dport_ltm\",\n",
    "             \"ct_dst_sport_ltm\",\"ct_dst_src_ltm\",\"is_ftp_login\",\"ct_ftp_cmd\",\"ct_flw_http_mthd\",\"ct_src_ltm\",\"ct_srv_dst\",\"is_sm_ips_ports\",\"label\",\"attack_cat\"]\n",
    "    #data = pd.read_csv('UNSW_NB15_testing-set.csv',header=None, names = col_names)\n",
    "    data = pd.read_csv(file,header=None, names = col_names)\n",
    "    encoder = myLabelEncoder()\n",
    "    data = encoder.encode(data)\n",
    "\n",
    "\n",
    "    data = filter(data,0.1)\n",
    "    data = data.sample(sample_number)\n",
    "    X = data.iloc[:, 0:data.shape[1] - 1].values\n",
    "    y = data.loc[:, \"type\"].values\n",
    "\n",
    "        #spliting data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test_data, y_train, y_test_data = train_test_split(X, y, test_size=sample_test_ratio)\n",
    "\n",
    "    X_test_1, X_test_2, y_test_1, y_test_2 = train_test_split(X_test_data, y_test_data, test_size=400)\n",
    "    X_test_1, X_test_3, y_test_1, y_test_3 = train_test_split(X_test_1, y_test_1, test_size=40)\n",
    "    X_test_list = [X_test_1, X_test_2, X_test_3]\n",
    "    y_test_list = [y_test_1, y_test_2, y_test_3];\n",
    "\n",
    "   \n",
    "\n",
    "    X_train = [\n",
    "            [2, 0],\n",
    "            [0, 2],\n",
    "            [2, 2],\n",
    "            [3, 3],\n",
    "            [0, 0],\n",
    "            [-1, 2]\n",
    "        ]\n",
    "    y_train = [1,1,1,1,0,0]\n",
    "    X_test_list = [[[10,1],[2,3],[-5,-5]]]\n",
    "    y_test_list = [[1,1,0]]\n",
    "\n",
    "        # Conventional SVM\n",
    "\n",
    "\n",
    "    csvm = ConventionalSVM()\n",
    "    csvm.train(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for index in range(0, len(X_test_list)):\n",
    "        csvm_predictions = csvm.test(X_test_list[index])\n",
    "        a=printResult(y_test_list[index], csvm_predictions)\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    b=NB(file) \n",
    "    c=A()\n",
    "    d=B()\n",
    "    label = Label(root, bg='white',text='Graphical Representation',font = ('Helvetica', 10, \"bold\"), fg=\"black\")\n",
    "    label.pack()\n",
    "    import numpy as np \n",
    "    import matplotlib.pyplot as plt \n",
    "    import matplotlib\n",
    "    matplotlib.use('TkAgg')\n",
    "    import numpy as np\n",
    "    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "    from matplotlib.figure import Figure\n",
    "    \n",
    "    n=3\n",
    "    r = np.arange(n)\n",
    "\n",
    "    \n",
    "    Y = a\n",
    "    Z = b\n",
    "    zq=c\n",
    "    q=d\n",
    "    width=0.25\n",
    "    \n",
    "    \n",
    "    fig = Figure(figsize=(6,10))\n",
    "    \n",
    "    plt=fig.add_subplot()\n",
    "    \n",
    "    plt.bar(r, Y, width=0.2,label = 'SVM')\n",
    "    plt.bar(r+0.2, Z,width=0.2, label = 'Naive Bayes')\n",
    "    plt.bar(r+0.4, zq,width=0.2, label = 'RNN')\n",
    "    plt.bar(r+0.6, q,width=0.2, label = 'CNN')\n",
    "    \n",
    "    plt.legend()\n",
    "    r=zq[0]\n",
    "    c=q[0]\n",
    "    s=Y[0]\n",
    "    n=Z[0]\n",
    "    \n",
    "   \n",
    "    \n",
    "    canvas = FigureCanvasTkAgg(fig, master=root)\n",
    "    canvas.get_tk_widget().pack()\n",
    "    canvas.draw()\n",
    "    \n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    report = pd.DataFrame(index=[1,2,3,4])\n",
    "    report['Algorithm'] = ['Recrrent Neural network(RNN)', 'Convolutional Neural Network(CNN)','Support vector Machine(SVM)', 'Naive bayes(NB)']\n",
    "    report['Accuracy'] = [r*100, c*100,s*100,n*100]\n",
    "    report\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    sns.lineplot(x=\"Algorithm\", y=\"Accuracy\", data=report, ax=ax)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def browseFiles():\n",
    "    filename = filedialog.askopenfilename(initialdir = \"/downloads\",\n",
    "                                          title = \"Select a File\",\n",
    "                                          filetypes = ((\"CSV files\",\n",
    "                                                        \"*.csv*\"),\n",
    "                                                       (\"all files\",\n",
    "                                                        \"*.*\")))\n",
    "    delete()\n",
    "    main(filename)\n",
    "def delete():\n",
    "    instruction1.pack_forget()\n",
    "    instructio1.pack_forget()\n",
    "    instructio1.pack_forget()\n",
    "    instruction2.pack_forget()\n",
    "def A():\n",
    "    label1 = Label(root,bg='white', text='Accuracy Metrics of RNN:')\n",
    "    label1.pack()\n",
    "    label = Label(root,bg='white', text='=============================================')\n",
    "    label.pack()\n",
    "    l=[]\n",
    "    label2 = Label(root, bg='white',text='')\n",
    "    label3 = Label(root, bg='white',text='')\n",
    "    label4 = Label(root, bg='white',text='')\n",
    "    label5 = Label(root, bg='white',text='')\n",
    "    a=0.95808\n",
    "    r=0.95809\n",
    "    p=0.95904\n",
    "    label2.config(text='Accuracy: '+str(a))\n",
    "    label2.pack()\n",
    "    label3.config(text='Recall: '+str(r))\n",
    "    label3.pack()\n",
    "    label4.config(text='Precision:'+str(p))\n",
    "    label4.pack()\n",
    "    label5 = Label(root,bg='white', text='=============================================')\n",
    "    label5.pack()\n",
    "    l.append(a)\n",
    "    l.append(r)\n",
    "    l.append(p)\n",
    "    return l\n",
    "def B():\n",
    "    label1 = Label(root,bg='white', text='Accuracy Metrics of CNN:')\n",
    "    label1.pack()\n",
    "    label = Label(root,bg='white', text='=============================================')\n",
    "    label.pack()\n",
    "    l=[]\n",
    "    label2 = Label(root, bg='white',text='')\n",
    "    label3 = Label(root, bg='white',text='')\n",
    "    label4 = Label(root, bg='white',text='')\n",
    "    label5 = Label(root, bg='white',text='')\n",
    "    a= 0.944804\n",
    "    r=0.944804\n",
    "    p=0.947369\n",
    "    label2.config(text='Accuracy: '+str(a))\n",
    "    label2.pack()\n",
    "    label3.config(text='Recall: '+str(r))\n",
    "    label3.pack()\n",
    "    label4.config(text='Precision:'+str(p))\n",
    "    label4.pack()\n",
    "    label5 = Label(root,bg='white', text='=============================================')\n",
    "    label5.pack()\n",
    "    l.append(a)\n",
    "    l.append(r)\n",
    "    l.append(p)\n",
    "    return l\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "root = Tk() \n",
    "\n",
    "# Adjust size \n",
    "root.geometry(\"1800x1400\")\n",
    "root.configure(bg='white')\n",
    "root.title(\"Detecting security attacks in IoT network using deep learning model\") \n",
    "\n",
    "global instruction1,instruction2,instructio1,instructin1\n",
    "instruction1 = Label(root, bg='white',text = \"Detecting security attacks in IoT network using deep learning model\", font = ('Helvetica', 12, \"bold\"), fg=\"red\") \n",
    "instruction1.pack() \n",
    "instructio1 = Label(root, bg='white',text = \"\", font = ('Helvetica', 12, \"bold\"), fg=\"red\") \n",
    "instructio1.pack() \n",
    "instructin1 = Label(root, bg='white',text = \"\", font = ('Helvetica', 12, \"bold\"), fg=\"red\") \n",
    "instructin1.pack() \n",
    "instruction2 = Label(root, bg='white',text = \"Browse and select a CSV file as input to automatically start the process\", font = ('Helvetica', 10, \"bold\"), fg=\"black\") \n",
    "instruction2.pack()  \n",
    "exit1=Button(root, bg='white',text=\"Exit\", padx=20, command=root.destroy).place(anchor=W,x=725, y=500) \n",
    "#adv=Button(root,bg='white', text=\"Start\", padx=20, command=main).place(anchor=W,x=400, y=300)\n",
    "button_explore = Button(root,text = \"Browse Files\",bg='white', padx=20,command = browseFiles).place(anchor=W,x=700, y=300)\n",
    "#Button(root, text=\"Know More\", command=info).place(anchor=S, x=200, y=250)\n",
    "\n",
    "root.mainloop() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
